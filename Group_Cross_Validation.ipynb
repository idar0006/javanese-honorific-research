{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e3b90-cc34-4bd0-9704-472e3f282da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to load data with different encodings\n",
    "def load_data(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Failed to decode the file with tried encodings.\")\n",
    "\n",
    "# Load the dataset\n",
    "df_all = load_data('df_all_group3.csv')\n",
    "\n",
    "# Ensure labels are integers\n",
    "df_all['label'] = df_all['label'].astype(int)\n",
    "\n",
    "# Perform group-aware split (80% train, 20% test)\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(df_all, groups=df_all['group']))\n",
    "df_train = df_all.loc[train_indices]\n",
    "df_test = df_all.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f94c2d-0c4c-4edc-ad22-a0680e28e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('df_test_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5b96f-e583-4b14-b259-eee469741a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train_group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5116e67b-2f04-486d-92ca-7997e869b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df_all = pd.read_csv('df_all_group3.csv')\n",
    "\n",
    "# Ensure labels are integers\n",
    "df_all['label'] = df_all['label'].astype(int)\n",
    "\n",
    "# Perform group-aware split (80% train, 20% test)\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(df_all, groups=df_all['group']))\n",
    "df_train = df_all.loc[train_indices]\n",
    "df_test = df_all.loc[test_indices]\n",
    "\n",
    "# Define metrics function\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
    "    accuracy = accuracy_score(p.label_ids, preds)\n",
    "    return {'accuracy': accuracy, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "# Model names\n",
    "model_names = [\n",
    "    \"w11wo/javanese-bert-small-imdb-classifier\",\n",
    "    \"w11wo/javanese-gpt2-small-imdb-classifier\",\n",
    "    \"w11wo/javanese-distilbert-small-imdb-classifier\"\n",
    "]\n",
    "\n",
    "# Fixed hyperparameters\n",
    "learning_rate = 5e-5\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "\n",
    "k_folds = 5\n",
    "gkf = GroupKFold(n_splits=k_folds)\n",
    "\n",
    "# Store cross-validation results for each model\n",
    "cross_val_results = []\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model_name in model_names:\n",
    "    print(f\"\\nCross-validating model: {model_name}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Prepare datasets for each fold\n",
    "    for fold, (train_index, val_index) in enumerate(gkf.split(df_train['sentence'], df_train['label'], groups=df_train['group'])):\n",
    "        print(f\"Fold {fold+1}\")\n",
    "        \n",
    "        train_data = df_train.iloc[train_index]\n",
    "        val_data = df_train.iloc[val_index]\n",
    "        \n",
    "        # Convert to Hugging Face datasets\n",
    "        train_dataset = Dataset.from_pandas(train_data)\n",
    "        val_dataset = Dataset.from_pandas(val_data)\n",
    "        \n",
    "        # Preprocess data\n",
    "        def preprocess_function(examples):\n",
    "            return tokenizer(examples['sentence'], truncation=True, padding='max_length', max_length=128)\n",
    "        \n",
    "        tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "        tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
    "        \n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "        \n",
    "        # Load model\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4, ignore_mismatched_sizes=True)\n",
    "        \n",
    "        # Define training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'/scratch/lf93/iw/group_result/{model_name}/fold_{fold}',\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_epochs,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",  # Save the model after each epoch\n",
    "            load_best_model_at_end=False,\n",
    "            push_to_hub=False\n",
    "        )\n",
    "        \n",
    "        # Initialize Trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_val,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "        \n",
    "        # Save the model after each fold\n",
    "        trainer.save_model(f'/scratch/lf93/iw/group_result/{model_name}/fold_{fold}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_results = trainer.predict(tokenized_val)\n",
    "        fold_metrics.append(compute_metrics(val_results))\n",
    "    \n",
    "    # Average metrics for the current model\n",
    "    avg_metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': np.mean([m['accuracy'] for m in fold_metrics]),\n",
    "        'F1 Score': np.mean([m['f1'] for m in fold_metrics]),\n",
    "        'Precision': np.mean([m['precision'] for m in fold_metrics]),\n",
    "        'Recall': np.mean([m['recall'] for m in fold_metrics])\n",
    "    }\n",
    "    cross_val_results.append(avg_metrics)\n",
    "\n",
    "# Create a DataFrame for the cross-validation results\n",
    "cross_val_results_df = pd.DataFrame(cross_val_results)\n",
    "\n",
    "# Display the cross-validation results table\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(cross_val_results_df)\n",
    "\n",
    "# Save the cross-validation results to a CSV file\n",
    "cross_val_results_df.to_csv('cross_val_results.csv', index=False)\n",
    "\n",
    "# Select the best model for each model type\n",
    "best_models = cross_val_results_df.loc[cross_val_results_df.groupby('Model')['F1 Score'].idxmax()]\n",
    "\n",
    "# Train and evaluate each best model on the test set\n",
    "test_results = []\n",
    "\n",
    "for model_name in best_models['Model']:\n",
    "    print(f\"\\nTraining and evaluating {model_name} on the test set.\")\n",
    "    \n",
    "    # Combine the train and validation data for the model\n",
    "    train_dataset = Dataset.from_pandas(df_train)\n",
    "    \n",
    "    # Preprocess the combined dataset\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples['sentence'], truncation=True, padding='max_length', max_length=128)\n",
    "    \n",
    "    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    # Load the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4, ignore_mismatched_sizes=True)\n",
    "    \n",
    "    # Define training arguments for final training\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'/scratch/lf93/iw/group_result/{model_name}/final',\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        push_to_hub=False\n",
    "    )\n",
    "    \n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train on the full combined dataset\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the final trained model\n",
    "    trainer.save_model(f'/scratch/lf93/iw/group_result/{model_name}/final_model')\n",
    "    \n",
    "    # Preprocess test data\n",
    "    test_dataset = Dataset.from_pandas(df_test)\n",
    "    tokenized_test = test_dataset.map(lambda x: tokenizer(x['sentence'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    test_results_output = trainer.predict(tokenized_test)\n",
    "    test_metrics = compute_metrics(test_results_output)\n",
    "    \n",
    "    # Store the test results\n",
    "    test_results.append({\n",
    "        'Model': model_name,\n",
    "        'Test Accuracy': test_metrics['accuracy'],\n",
    "        'Test F1 Score': test_metrics['f1'],\n",
    "        'Test Precision': test_metrics['precision'],\n",
    "        'Test Recall': test_metrics['recall']\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for the final results\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "# Display the final test results table\n",
    "print(\"\\nTest Set Evaluation Results:\")\n",
    "print(test_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821280db-7891-4ea4-b7d7-a84b5cfdcdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
