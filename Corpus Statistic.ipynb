{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59bb023-6e69-4329-a424-f00a9201025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lexical-diversity\n",
      "  Downloading lexical_diversity-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Downloading lexical_diversity-0.1.1-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: lexical-diversity\n",
      "Successfully installed lexical-diversity-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lexical-diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca22a8de-0f01-43d7-9d1c-0125d9cd13cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of Sentences  Average Sentence Length  Number of Word Tokens   \n",
      "0                 4024                 9.628728                  38746  \\\n",
      "\n",
      "   Number of Word Types  Yule’s Characteristic K  \n",
      "0                  6156               105.434295  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Function to load data with different encodings\n",
    "def load_data(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Failed to decode the file with tried encodings.\")\n",
    "\n",
    "# Load the dataset\n",
    "data = load_data('df_all_group3.csv')\n",
    "\n",
    "# Extract the 'sentence' column\n",
    "sentences = data['sentence'].dropna().tolist()\n",
    "\n",
    "# Tokenize each sentence into words\n",
    "words = [word_tokenize(sent) for sent in sentences]\n",
    "words = [word for sublist in words for word in sublist]\n",
    "\n",
    "# Calculate the number of sentences\n",
    "num_sentences = len(sentences)\n",
    "\n",
    "# Calculate the average sentence length\n",
    "avg_sentence_length = np.mean([len(word_tokenize(sent)) for sent in sentences])\n",
    "\n",
    "# Calculate the number of word tokens\n",
    "num_word_tokens = len(words)\n",
    "\n",
    "# Calculate the number of word types\n",
    "num_word_types = len(set(words))\n",
    "\n",
    "# Calculate Yule’s characteristic K\n",
    "word_counts = Counter(words)\n",
    "V_m = Counter(word_counts.values())\n",
    "K = 10**4 * (sum(m**2 * V_m[m] for m in V_m) - num_word_tokens) / num_word_tokens**2\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    'Number of Sentences': num_sentences,\n",
    "    'Average Sentence Length': avg_sentence_length,\n",
    "    'Number of Word Tokens': num_word_tokens,\n",
    "    'Number of Word Types': num_word_types,\n",
    "    'Yule’s Characteristic K': K\n",
    "}\n",
    "\n",
    "# Print results as a DataFrame\n",
    "results_df = pd.DataFrame([results])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f93d1b-70f9-4061-a938-7b2ac67293df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Number of Word Tokens</th>\n",
       "      <th>Number of Word Types</th>\n",
       "      <th>Yule’s Characteristic K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4024</td>\n",
       "      <td>9.628728</td>\n",
       "      <td>38746</td>\n",
       "      <td>6156</td>\n",
       "      <td>105.434295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Sentences  Average Sentence Length  Number of Word Tokens   \n",
       "0                 4024                 9.628728                  38746  \\\n",
       "\n",
       "   Number of Word Types  Yule’s Characteristic K  \n",
       "0                  6156               105.434295  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1482271b-56d9-4785-a72d-142a055b84cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Numerical Label Text Label  Number of Sentences  Average Sentence Length   \n",
      "0           Total      Total                 4024                 9.628728  \\\n",
      "\n",
      "   Number of Word Tokens  Number of Word Types  Yule’s Characteristic K  \n",
      "0                  38746                  6156               105.434295  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Function to load data with different encodings\n",
    "def load_data(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Failed to decode the file with tried encodings.\")\n",
    "\n",
    "# Function to analyze text data for a specific label\n",
    "def analyze_text(sentences):\n",
    "    words = [word_tokenize(sent) for sent in sentences]\n",
    "    words = [word for sublist in words for word in sublist]\n",
    "\n",
    "    num_sentences = len(sentences)\n",
    "    avg_sentence_length = np.mean([len(word_tokenize(sent)) for sent in sentences])\n",
    "    num_word_tokens = len(words)\n",
    "    num_word_types = len(set(words))\n",
    "\n",
    "    word_counts = Counter(words)\n",
    "    V_m = Counter(word_counts.values())\n",
    "    K = 10**4 * (sum(m**2 * V_m[m] for m in V_m) - num_word_tokens) / num_word_tokens**2\n",
    "\n",
    "    return {\n",
    "        'Number of Sentences': num_sentences,\n",
    "        'Average Sentence Length': avg_sentence_length,\n",
    "        'Number of Word Tokens': num_word_tokens,\n",
    "        'Number of Word Types': num_word_types,\n",
    "        'Yule’s Characteristic K': K\n",
    "    }\n",
    "\n",
    "# Load the dataset\n",
    "data = load_data('df_all_group3.csv')\n",
    "\n",
    "# # Ensure 'label' column is treated as string\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "# # Label mapping\n",
    "label_mapping = {'n': 0, 'na': 1, 'k': 2, 'ka': 3}\n",
    "inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map textual labels to numerical labels\n",
    "# data['numerical_label'] = data['class'].map(label_mapping)\n",
    "data['numerical_label'] = data['label']\n",
    "\n",
    "# Analyze text data for each label\n",
    "results = []\n",
    "for numerical_label, text_label in inverse_label_mapping.items():\n",
    "    group = data[data['numerical_label'] == numerical_label]\n",
    "    sentences = group['sentence'].dropna().tolist()\n",
    "    if sentences:  # Ensure there are sentences to analyze\n",
    "        analysis = analyze_text(sentences)\n",
    "        analysis['Numerical Label'] = numerical_label\n",
    "        analysis['Text Label'] = text_label\n",
    "        results.append(analysis)\n",
    "\n",
    "# Perform analysis on the entire dataset\n",
    "all_sentences = data['sentence'].dropna().tolist()\n",
    "total_analysis = analyze_text(all_sentences)\n",
    "total_analysis['Numerical Label'] = 'Total'\n",
    "total_analysis['Text Label'] = 'Total'\n",
    "\n",
    "# Append the total analysis to the results\n",
    "results.append(total_analysis)\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns to have 'Numerical Label' and 'Text Label' first\n",
    "results_df = results_df[['Numerical Label', 'Text Label', 'Number of Sentences', 'Average Sentence Length', 'Number of Word Tokens', 'Number of Word Types', 'Yule’s Characteristic K']]\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578b31c0-62f0-4495-bcdc-4b6a379d3c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Function to load data with different encodings\n",
    "def load_data(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Failed to decode the file with tried encodings.\")\n",
    "\n",
    "# Function to analyze text data for a specific label\n",
    "def analyze_text(sentences):\n",
    "    words = [word_tokenize(sent) for sent in sentences]\n",
    "    words = [word for sublist in words for word in sublist]\n",
    "\n",
    "    num_sentences = len(sentences)\n",
    "    avg_sentence_length = np.mean([len(word_tokenize(sent)) for sent in sentences])\n",
    "    num_word_tokens = len(words)\n",
    "    num_word_types = len(set(words))\n",
    "\n",
    "    word_counts = Counter(words)\n",
    "    V_m = Counter(word_counts.values())\n",
    "    K = 10**4 * (sum(m**2 * V_m[m] for m in V_m) - num_word_tokens) / num_word_tokens**2\n",
    "\n",
    "    return {\n",
    "        'Number of Sentences': num_sentences,\n",
    "        'Average Sentence Length': avg_sentence_length,\n",
    "        'Number of Word Tokens': num_word_tokens,\n",
    "        'Number of Word Types': num_word_types,\n",
    "        'Yule’s Characteristic K': K\n",
    "    }\n",
    "\n",
    "# Load the dataset\n",
    "data = load_data('df_all_group3.csv')\n",
    "\n",
    "# Ensure 'label' column is treated as string\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "# Label mapping based on the table (assuming labels 0, 1, 2, 3 match with ngoko, ngoko alus, krama, krama alus)\n",
    "label_mapping = {0: 'Ngoko', 1: 'Ngoko Alus', 2: 'Krama', 3: 'Krama Alus'}\n",
    "inverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Map textual labels to numerical labels\n",
    "data['numerical_label'] = data['label']\n",
    "\n",
    "# Analyze text data for each label\n",
    "results = []\n",
    "for numerical_label, text_label in label_mapping.items():\n",
    "    group = data[data['numerical_label'] == str(numerical_label)]\n",
    "    sentences = group['sentence'].dropna().tolist()\n",
    "    if sentences:  # Ensure there are sentences to analyze\n",
    "        analysis = analyze_text(sentences)\n",
    "        analysis['Numerical Label'] = numerical_label\n",
    "        analysis['Text Label'] = text_label\n",
    "        results.append(analysis)\n",
    "\n",
    "# Perform analysis on the entire dataset\n",
    "all_sentences = data['sentence'].dropna().tolist()\n",
    "total_analysis = analyze_text(all_sentences)\n",
    "total_analysis['Numerical Label'] = 'Total'\n",
    "total_analysis['Text Label'] = 'Total'\n",
    "\n",
    "# Append the total analysis to the results\n",
    "results.append(total_analysis)\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Reorder columns to match the format in the image\n",
    "results_df = results_df[['Text Label', 'Number of Sentences', 'Average Sentence Length', 'Number of Word Tokens', 'Number of Word Types', 'Yule’s Characteristic K']]\n",
    "\n",
    "# Format the numerical columns to two decimal places\n",
    "results_df['Average Sentence Length'] = results_df['Average Sentence Length'].apply(lambda x: f\"{x:.2f}\")\n",
    "results_df['Yule’s Characteristic K'] = results_df['Yule’s Characteristic K'].apply(lambda x: f\"{x:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0138efb6-3cd0-47d2-98cb-4af30c7fc666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Label</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Number of Word Tokens</th>\n",
       "      <th>Number of Word Types</th>\n",
       "      <th>Yule’s Characteristic K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngoko</td>\n",
       "      <td>1419</td>\n",
       "      <td>9.26</td>\n",
       "      <td>13142</td>\n",
       "      <td>3486</td>\n",
       "      <td>118.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ngoko Alus</td>\n",
       "      <td>590</td>\n",
       "      <td>10.07</td>\n",
       "      <td>5944</td>\n",
       "      <td>1527</td>\n",
       "      <td>108.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Krama</td>\n",
       "      <td>1414</td>\n",
       "      <td>9.60</td>\n",
       "      <td>13572</td>\n",
       "      <td>3280</td>\n",
       "      <td>124.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Krama Alus</td>\n",
       "      <td>601</td>\n",
       "      <td>10.13</td>\n",
       "      <td>6088</td>\n",
       "      <td>1530</td>\n",
       "      <td>115.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total</td>\n",
       "      <td>4024</td>\n",
       "      <td>9.63</td>\n",
       "      <td>38746</td>\n",
       "      <td>6156</td>\n",
       "      <td>105.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text Label  Number of Sentences Average Sentence Length   \n",
       "0       Ngoko                 1419                    9.26  \\\n",
       "1  Ngoko Alus                  590                   10.07   \n",
       "2       Krama                 1414                    9.60   \n",
       "3  Krama Alus                  601                   10.13   \n",
       "4       Total                 4024                    9.63   \n",
       "\n",
       "   Number of Word Tokens  Number of Word Types Yule’s Characteristic K  \n",
       "0                  13142                  3486                  118.80  \n",
       "1                   5944                  1527                  108.13  \n",
       "2                  13572                  3280                  124.61  \n",
       "3                   6088                  1530                  115.14  \n",
       "4                  38746                  6156                  105.43  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b8c12f-dcad-429b-96fa-95a2503c3ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-Domain Results for df_all_group3.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Label</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Number of Word Tokens</th>\n",
       "      <th>Number of Word Types</th>\n",
       "      <th>Yule’s Characteristic K</th>\n",
       "      <th>MATTR</th>\n",
       "      <th>MSTTR</th>\n",
       "      <th>MTLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngoko</td>\n",
       "      <td>1419</td>\n",
       "      <td>9.26</td>\n",
       "      <td>13142</td>\n",
       "      <td>3486</td>\n",
       "      <td>118.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>124.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ngoko Alus</td>\n",
       "      <td>590</td>\n",
       "      <td>10.07</td>\n",
       "      <td>5944</td>\n",
       "      <td>1527</td>\n",
       "      <td>108.13</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>106.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Krama</td>\n",
       "      <td>1414</td>\n",
       "      <td>9.60</td>\n",
       "      <td>13572</td>\n",
       "      <td>3280</td>\n",
       "      <td>124.61</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>93.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Krama Alus</td>\n",
       "      <td>601</td>\n",
       "      <td>10.13</td>\n",
       "      <td>6088</td>\n",
       "      <td>1530</td>\n",
       "      <td>115.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>94.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total</td>\n",
       "      <td>4024</td>\n",
       "      <td>9.63</td>\n",
       "      <td>38746</td>\n",
       "      <td>6156</td>\n",
       "      <td>105.43</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>104.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text Label  Number of Sentences  Average Sentence Length   \n",
       "0       Ngoko                 1419                     9.26  \\\n",
       "1  Ngoko Alus                  590                    10.07   \n",
       "2       Krama                 1414                     9.60   \n",
       "3  Krama Alus                  601                    10.13   \n",
       "4       Total                 4024                     9.63   \n",
       "\n",
       "   Number of Word Tokens  Number of Word Types  Yule’s Characteristic K   \n",
       "0                  13142                  3486                   118.80  \\\n",
       "1                   5944                  1527                   108.13   \n",
       "2                  13572                  3280                   124.61   \n",
       "3                   6088                  1530                   115.14   \n",
       "4                  38746                  6156                   105.43   \n",
       "\n",
       "   MATTR  MSTTR    MTLD  \n",
       "0   0.81   0.81  124.26  \n",
       "1   0.81   0.81  106.08  \n",
       "2   0.80   0.79   93.65  \n",
       "3   0.80   0.80   94.81  \n",
       "4   0.80   0.80  104.70  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-Domain Results for news.csv and magz.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Label</th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Number of Word Tokens</th>\n",
       "      <th>Number of Word Types</th>\n",
       "      <th>Yule’s Characteristic K</th>\n",
       "      <th>MATTR</th>\n",
       "      <th>MSTTR</th>\n",
       "      <th>MTLD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ngoko</td>\n",
       "      <td>885</td>\n",
       "      <td>15.86</td>\n",
       "      <td>14033</td>\n",
       "      <td>3402</td>\n",
       "      <td>98.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>83.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krama Alus</td>\n",
       "      <td>369</td>\n",
       "      <td>15.48</td>\n",
       "      <td>5712</td>\n",
       "      <td>1824</td>\n",
       "      <td>110.34</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>71.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>1254</td>\n",
       "      <td>15.75</td>\n",
       "      <td>19745</td>\n",
       "      <td>4916</td>\n",
       "      <td>94.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>77.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text Label  Number of Sentences  Average Sentence Length   \n",
       "0       Ngoko                  885                    15.86  \\\n",
       "1  Krama Alus                  369                    15.48   \n",
       "2       Total                 1254                    15.75   \n",
       "\n",
       "   Number of Word Tokens  Number of Word Types  Yule’s Characteristic K   \n",
       "0                  14033                  3402                    98.79  \\\n",
       "1                   5712                  1824                   110.34   \n",
       "2                  19745                  4916                    94.45   \n",
       "\n",
       "   MATTR  MSTTR   MTLD  \n",
       "0   0.79   0.79  83.72  \n",
       "1   0.77   0.77  71.17  \n",
       "2   0.78   0.78  77.45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from lexical_diversity import lex_div as ld\n",
    "\n",
    "# Function to load data with different encodings\n",
    "def load_data(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'ISO-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"Failed to decode the file with tried encodings.\")\n",
    "\n",
    "# Function to analyze text data for a specific label\n",
    "def analyze_text(sentences):\n",
    "    tokenized_sentences = [word_tokenize(sent) for sent in sentences]\n",
    "    words = [word for sentence in tokenized_sentences for word in sentence]\n",
    "\n",
    "    num_sentences = len(sentences)\n",
    "    avg_sentence_length = np.mean([len(sentence) for sentence in tokenized_sentences])\n",
    "    num_word_tokens = len(words)\n",
    "    num_word_types = len(set(words))\n",
    "\n",
    "    word_counts = Counter(words)\n",
    "    V_m = Counter(word_counts.values())\n",
    "    K = 10**4 * (sum(m**2 * V_m[m] for m in V_m) - num_word_tokens) / num_word_tokens**2\n",
    "\n",
    "    # Calculate MATTR, MSTTR, and MTLD\n",
    "    mattr = ld.mattr(words)\n",
    "    msttr = ld.msttr(words)\n",
    "    mtld = ld.mtld(words)\n",
    "\n",
    "    return {\n",
    "        'Number of Sentences': num_sentences,\n",
    "        'Average Sentence Length': avg_sentence_length,\n",
    "        'Number of Word Tokens': num_word_tokens,\n",
    "        'Number of Word Types': num_word_types,\n",
    "        'Yule’s Characteristic K': K,\n",
    "        'MATTR': mattr,\n",
    "        'MSTTR': msttr,\n",
    "        'MTLD': mtld\n",
    "    }\n",
    "\n",
    "# Function to analyze and display results for a given dataset\n",
    "def analyze_dataset(data, label_mapping):\n",
    "    data['label'] = data['label'].astype(str)\n",
    "\n",
    "    results = []\n",
    "    mattr_values = []\n",
    "    msttr_values = []\n",
    "    mtld_values = []\n",
    "    for numerical_label, text_label in label_mapping.items():\n",
    "        group = data[data['label'] == str(numerical_label)]\n",
    "        sentences = group['sentence'].dropna().tolist()\n",
    "        if sentences:  # Ensure there are sentences to analyze\n",
    "            analysis = analyze_text(sentences)\n",
    "            analysis['Numerical Label'] = numerical_label\n",
    "            analysis['Text Label'] = text_label\n",
    "            results.append(analysis)\n",
    "            mattr_values.append(analysis['MATTR'])\n",
    "            msttr_values.append(analysis['MSTTR'])\n",
    "            mtld_values.append(analysis['MTLD'])\n",
    "\n",
    "    # Perform analysis on the entire dataset\n",
    "    all_sentences = data['sentence'].dropna().tolist()\n",
    "    total_analysis = analyze_text(all_sentences)\n",
    "    total_analysis['Numerical Label'] = 'Total'\n",
    "    total_analysis['Text Label'] = 'Total'\n",
    "    total_analysis['MATTR'] = np.mean(mattr_values)  # Calculate total MATTR as the average of all labels\n",
    "    total_analysis['MSTTR'] = np.mean(msttr_values)  # Calculate total MSTTR as the average of all labels\n",
    "    total_analysis['MTLD'] = np.mean(mtld_values)  # Calculate total MTLD as the average of all labels\n",
    "\n",
    "    # Append the total analysis to the results\n",
    "    results.append(total_analysis)\n",
    "\n",
    "    # Convert results to DataFrame and return\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Reorder columns to match the format in the image\n",
    "    results_df = results_df[['Text Label', 'Number of Sentences', 'Average Sentence Length', 'Number of Word Tokens', 'Number of Word Types', 'Yule’s Characteristic K', 'MATTR', 'MSTTR', 'MTLD']]\n",
    "\n",
    "    # Format the numerical columns to two decimal places\n",
    "    for col in ['Average Sentence Length', 'Yule’s Characteristic K', 'MATTR', 'MSTTR', 'MTLD']:\n",
    "        results_df[col] = results_df[col].astype(float).round(2)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Label mapping based on the table (assuming labels 0, 1, 2, 3 match with ngoko, ngoko alus, krama, krama alus)\n",
    "label_mapping = {0: 'Ngoko', 1: 'Ngoko Alus', 2: 'Krama', 3: 'Krama Alus'}\n",
    "\n",
    "# Analyze and display results for in-domain dataset (df_all_group3.csv)\n",
    "results_df_all_group3 = analyze_dataset(load_data('df_all_group3.csv'), label_mapping)\n",
    "print(\"In-Domain Results for df_all_group3.csv:\")\n",
    "display(results_df_all_group3)\n",
    "\n",
    "# Combine and analyze out-of-domain datasets (news.csv and magz.csv)\n",
    "out_of_domain_data = pd.concat([load_data('news.csv'), load_data('magz.csv')], ignore_index=True)\n",
    "\n",
    "# Analyze out-of-domain dataset\n",
    "out_of_domain_results = analyze_dataset(out_of_domain_data, label_mapping)\n",
    "print(\"Out-of-Domain Results for news.csv and magz.csv:\")\n",
    "display(out_of_domain_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dcf60-e589-4396-90e3-6f21fc70a9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
